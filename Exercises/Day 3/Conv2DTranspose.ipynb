{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "B22wowEP9SWl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import models,transforms\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### When the input is of size 31x31"
      ],
      "metadata": {
        "id": "G4Hmlsv_thKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_image = torch.rand((1,10,31,31))\n",
        "random_image.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBar4yQrO2mn",
        "outputId": "6236618a-de67-42c4-b8c1-712e5ff9ee2a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10, 31, 31])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv2d_output = nn.Conv2d(in_channels=10,out_channels=20,kernel_size=3,padding=1, stride=2)(random_image)\n",
        "conv2d_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txzUN0NsO9qF",
        "outputId": "8020aa09-db87-4cd8-a540-212a5b1d13c7"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 20, 16, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We get the same output shape as our original image."
      ],
      "metadata": {
        "id": "u79olNN-tnxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "convtranspose2d_output = nn.ConvTranspose2d(in_channels=20,out_channels=10,kernel_size=3,padding=1, stride=2)(conv2d_output)\n",
        "convtranspose2d_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvIARGPsQO4V",
        "outputId": "92853efd-c4b1-4eff-adfb-57a34939bcfc"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10, 31, 31])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dEm0JOS4cDUi"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### When the input is of size 32x32"
      ],
      "metadata": {
        "id": "WhWUIOSOtcr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_image = torch.rand((1,10,32,32))\n",
        "random_image.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e003d039-ae31-4a57-da14-3e3da1972e57",
        "id": "DZBfFigBtXzj"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv2d_output = nn.Conv2d(in_channels=10,out_channels=20,kernel_size=3,padding=1, stride=2)(random_image)\n",
        "conv2d_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d43f8b13-4cc4-462d-f65d-b32607b750b1",
        "id": "CuDHg_VWtXzm"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 20, 16, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output shape does not match the original input image shape"
      ],
      "metadata": {
        "id": "_iODOxnYu2Ku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "convtranspose2d_output = nn.ConvTranspose2d(in_channels=20,out_channels=10,kernel_size=3,padding=1, stride=2)(conv2d_output)\n",
        "convtranspose2d_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b83bba22-ad91-45bf-8cf0-3a31dbe3628c",
        "id": "surGFy6LtXzm"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10, 31, 31])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to add some output padding in the conve Transpose layer."
      ],
      "metadata": {
        "id": "BXyJiJjzu60z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "convtranspose2d_output = nn.ConvTranspose2d(in_channels=20,out_channels=10,kernel_size=3,padding=1, stride=2, output_padding=1)(conv2d_output)\n",
        "convtranspose2d_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceC_prM8uypO",
        "outputId": "c54faa28-8f0a-492f-8767-57b0e794b632"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UDmNhQuSvAWT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}