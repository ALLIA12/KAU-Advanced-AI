{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Fine Tuning\n",
        "\n",
        "In several machine learning applcations, state of the art modles that work on \"similar\" problems are availabel.\n",
        "\n",
        "Rather than training a network from scratch, it is worthwhile to use the already available model, albeit they are for a slightly different problem\n",
        "\n",
        "This is called transfer learning. Possibly the simplest form of transfer learning is Fine-tuning where we make minor adjustments to a network and use it for a new problems.\n",
        "\n",
        "Fine-tuning is especially effective in cases where limited data is available.\n",
        "\n",
        "Let's explore example of fine-tunign below. We will fine-tune resent18 trained on imagenet"
      ],
      "metadata": {
        "id": "6UJrf5Wg_7Oa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboard"
      ],
      "metadata": {
        "id": "658EoBO6FCQC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16e6c336-2975-4296-a194-0585b533e646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.12.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.57.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.4.4)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.3.7)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.41.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTXa_TWbE5-N"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import models,transforms\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchsummary import summary\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST\n",
        "def mnist(batch_sz, valid_size=0.2, shuffle=True, random_seed=2000):\n",
        "    num_classes = 10\n",
        "    transform_train = transforms.Compose([\n",
        "                        transforms.RandomCrop(28, padding=4),\n",
        "                        transforms.ToTensor(),\n",
        "                    ])\n",
        "\n",
        "    transform_valid = transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                    ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                    ])\n",
        "\n",
        "\n",
        "    # Training dataset\n",
        "    train_data = MNIST(root='./datasets', train=True, download=True, transform=transform_train)\n",
        "    valid_data = MNIST(root='./datasets', train=True, download=True, transform=transform_valid)\n",
        "    num_train = len(train_data)\n",
        "    indices = list(range(num_train))\n",
        "    split = int(np.floor(valid_size * num_train))\n",
        "    if shuffle == True:\n",
        "        np.random.seed(random_seed)\n",
        "        np.random.shuffle(indices)\n",
        "    train_idx, valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_sz, sampler=train_sampler,pin_memory=True)\n",
        "    valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_sz, sampler=valid_sampler,pin_memory=True)\n",
        "\n",
        "    # Test dataset\n",
        "    test_data = MNIST(root='./datasets', train=False, download=True, transform=transform_test)\n",
        "    test_loader = torch.utils.data.DataLoader(test_data,\n",
        "                                              batch_size=batch_sz, shuffle=False, pin_memory=True)\n",
        "\n",
        "    return train_loader, valid_loader, test_loader\n",
        "\n"
      ],
      "metadata": {
        "id": "ZF2RZgvYFEmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_sz=64 # this is batch size i.e. the number of rows in a batch of data\n",
        "train_loader, valid_loader, test_loader=mnist(batch_sz)"
      ],
      "metadata": {
        "id": "DzC-yrpaFG3Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94507f2e-af9d-4d2b-c9d3-7e7e6e9781be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./datasets/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 246247630.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./datasets/MNIST/raw/train-images-idx3-ubyte.gz to ./datasets/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./datasets/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 27160469.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./datasets/MNIST/raw/train-labels-idx1-ubyte.gz to ./datasets/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./datasets/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 155567108.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./datasets/MNIST/raw/t10k-images-idx3-ubyte.gz to ./datasets/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 5774637.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./datasets/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training Resnet from pre-trained weights\n",
        "\n",
        "#specify a folder under run for tensorboard data for the training\n",
        "writer = SummaryWriter(\"runs/lr_1\")\n",
        "\n",
        "device=torch.device('cuda:0')\n",
        "\n",
        "\n",
        "net=models.resnet18(pretrained=True)\n",
        "net.conv1=nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "net.fc=nn.Linear (in_features=512, out_features=10, bias=True)\n",
        "\n",
        "net=net.to(device)\n",
        "lr=.01\n",
        "momentum=0.5\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n",
        "lr_scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9, verbose=True)\n",
        "\n",
        "\n",
        "ls=[]\n",
        "for i in range(5):\n",
        "  loss_total=0\n",
        "  loss_val=0\n",
        "  acc_train=0\n",
        "  total_train=0\n",
        "  for ii,batch in enumerate(train_loader):\n",
        "    data=batch[0]\n",
        "    label=batch[1]\n",
        "    #optimizer-->buffer += grad\n",
        "    optimizer.zero_grad()\n",
        "    data, label = data.to(device), label.to(device)\n",
        "    logits = net(data)\n",
        "    #this is the output of the network and it's shape is batch_size X no of classes\n",
        "    loss = F.cross_entropy(logits, label)\n",
        "    loss_total+=loss.item()\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    out=torch.argmax(logits, dim=1)\n",
        "    acc_train+=torch.sum(out==label)\n",
        "    total_train+=logits.shape[0]\n",
        "\n",
        "  acc_val=0\n",
        "  total_val=0\n",
        "  with torch.no_grad():\n",
        "    for jj,batch in enumerate(valid_loader):\n",
        "          data=batch[0]\n",
        "          label=batch[1]\n",
        "          #optimizer-->buffer += grad\n",
        "          data, label = data.to(device), label.to(device)\n",
        "          logits = net(data)\n",
        "          loss = F.cross_entropy(logits, label)\n",
        "          loss_val+=loss.item()\n",
        "          out=torch.argmax(logits, dim=1)\n",
        "          acc_val+=torch.sum(out==label)\n",
        "          total_val+=logits.shape[0]\n",
        "\n",
        "\n",
        "\n",
        "  ls.append(loss_total)\n",
        "  lr_scheduler.step()\n",
        "  print(f\"Iterataion {i}: Training Loss: {loss_total/ii}, Validation Loss: {loss_val/jj}\")\n",
        "  print(f\"Iteataion {i}: Training Accuracy: {acc_train.item()/total_train}, Validation Accuracy  {acc_val.item()/total_val}\")\n",
        "  writer.add_scalar('Loss/train', loss_total/ii, i)\n",
        "  writer.add_scalar('Loss/test', loss_val/jj, i)\n",
        "  writer.add_scalar('Accuracy/train', acc_train.item()/total_train, i)\n",
        "  writer.add_scalar('Accuracy/test', acc_val.item()/total_val, i)\n",
        "plt.plot(ls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "T8lIWknNFJxC",
        "outputId": "9e64c711-f548-462f-c338-58869195f139"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adjusting learning rate of group 0 to 1.0000e-02.\n",
            "Adjusting learning rate of group 0 to 9.0000e-03.\n",
            "Iterataion 0: Training Loss: 0.278371469932142, Validation Loss: 0.10571582024956849\n",
            "Iteataion 0: Training Accuracy: 0.9122916666666666, Validation Accuracy  0.96725\n",
            "Adjusting learning rate of group 0 to 8.1000e-03.\n",
            "Iterataion 1: Training Loss: 0.09802068936861107, Validation Loss: 0.07202396945739016\n",
            "Iteataion 1: Training Accuracy: 0.97, Validation Accuracy  0.9789166666666667\n",
            "Adjusting learning rate of group 0 to 7.2900e-03.\n",
            "Iterataion 2: Training Loss: 0.06890438195847681, Validation Loss: 0.058477658731738394\n",
            "Iteataion 2: Training Accuracy: 0.9787916666666666, Validation Accuracy  0.982\n",
            "Adjusting learning rate of group 0 to 6.5610e-03.\n",
            "Iterataion 3: Training Loss: 0.055944313640234986, Validation Loss: 0.047079404539622886\n",
            "Iteataion 3: Training Accuracy: 0.9832083333333334, Validation Accuracy  0.98625\n",
            "Adjusting learning rate of group 0 to 5.9049e-03.\n",
            "Iterataion 4: Training Loss: 0.044618418579175076, Validation Loss: 0.046894737380497\n",
            "Iteataion 4: Training Accuracy: 0.9865833333333334, Validation Accuracy  0.9863333333333333\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fc6b5008bd0>]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Fine=tuning just the first and last layer\n",
        "\n",
        "#specify a folder under run for tensorboard data for the training\n",
        "writer = SummaryWriter(\"runs/lr_1\")\n",
        "\n",
        "device=torch.device('cuda:0')\n",
        "\n",
        "\n",
        "net=models.resnet18(pretrained=True)\n",
        "for layer in net.parameters():\n",
        "  layer.requires_grad=False\n",
        "net.conv1=nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "net.fc=nn.Linear (in_features=512, out_features=10, bias=True)\n",
        "\n",
        "for name,layer in net.named_parameters():\n",
        "  print(f\"layer {name} has requires_grad {layer.requires_grad}\")\n",
        "net=net.to(device)\n",
        "lr=.01\n",
        "momentum=0.5\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n",
        "lr_scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9, verbose=True)\n",
        "\n",
        "\n",
        "ls=[]\n",
        "for i in range(5):\n",
        "  loss_total=0\n",
        "  loss_val=0\n",
        "  acc_train=0\n",
        "  total_train=0\n",
        "  for ii,batch in enumerate(train_loader):\n",
        "    data=batch[0]\n",
        "    label=batch[1]\n",
        "    #optimizer-->buffer += grad\n",
        "    optimizer.zero_grad()\n",
        "    data, label = data.to(device), label.to(device)\n",
        "    logits = net(data)\n",
        "    #this is the output of the network and it's shape is batch_size X no of classes\n",
        "    loss = F.cross_entropy(logits, label)\n",
        "    loss_total+=loss.item()\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    out=torch.argmax(logits, dim=1)\n",
        "    acc_train+=torch.sum(out==label)\n",
        "    total_train+=logits.shape[0]\n",
        "\n",
        "  acc_val=0\n",
        "  total_val=0\n",
        "  with torch.no_grad():\n",
        "    for jj,batch in enumerate(valid_loader):\n",
        "          data=batch[0]\n",
        "          label=batch[1]\n",
        "          #optimizer-->buffer += grad\n",
        "          data, label = data.to(device), label.to(device)\n",
        "          logits = net(data)\n",
        "          loss = F.cross_entropy(logits, label)\n",
        "          loss_val+=loss.item()\n",
        "          out=torch.argmax(logits, dim=1)\n",
        "          acc_val+=torch.sum(out==label)\n",
        "          total_val+=logits.shape[0]\n",
        "\n",
        "\n",
        "\n",
        "  ls.append(loss_total)\n",
        "  lr_scheduler.step()\n",
        "  print(f\"Iterataion {i}: Training Loss: {loss_total/ii}, Validation Loss: {loss_val/jj}\")\n",
        "  print(f\"Iteataion {i}: Training Accuracy: {acc_train.item()/total_train}, Validation Accuracy  {acc_val.item()/total_val}\")\n",
        "  writer.add_scalar('Loss/train', loss_total/ii, i)\n",
        "  writer.add_scalar('Loss/test', loss_val/jj, i)\n",
        "  writer.add_scalar('Accuracy/train', acc_train.item()/total_train, i)\n",
        "  writer.add_scalar('Accuracy/test', acc_val.item()/total_val, i)\n",
        "plt.plot(ls)"
      ],
      "metadata": {
        "id": "WO0gbalMFkf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name,layer in net.named_parameters():\n",
        "  print(f\"{name}has requires_grad {layer.requires_grad}\")"
      ],
      "metadata": {
        "id": "c2kXx9FLFoL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5fOuuOzYFxus"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}